{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by [Gameli Ladzekpo](mailto:gameli.Ladzekpo@gmail.com) (Twitter/IG: @gamladz)\n",
    "\n",
    "For [AI Core](theaicore.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv') \n",
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             prod_price   R-squared:                       0.260\nModel:                            OLS   Adj. R-squared:                  0.238\nMethod:                 Least Squares   F-statistic:                     12.05\nDate:                Wed, 24 Feb 2021   Prob (F-statistic):           5.08e-21\nTime:                        13:03:22   Log-Likelihood:                -2388.3\nNo. Observations:                 425   AIC:                             4803.\nDf Residuals:                     412   BIC:                             4855.\nDf Model:                          12                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nconst           12.3608      5.239      2.359      0.019       2.061      22.660\nvolume_avg    6.039e-14   1.49e-14      4.062      0.000    3.12e-14    8.96e-14\nlength_avg    1.718e-14   5.15e-15      3.336      0.001    7.06e-15    2.73e-14\ndiameter_avg    -1.0922      0.616     -1.774      0.077      -2.303       0.118\ndepth_avg       -0.8136      1.334     -0.610      0.542      -3.436       1.809\nwidth_avg       -0.1997      0.627     -0.318      0.750      -1.433       1.034\nheight_avg    1.681e-15   8.46e-15      0.199      0.843   -1.49e-14    1.83e-14\nis_plant         0.0504      9.027      0.006      0.996     -17.695      17.795\nin_outdoor     -21.5423     15.131     -1.424      0.155     -51.287       8.202\nis_white        97.4228      9.093     10.714      0.000      79.549     115.297\nis_grey         22.4547     10.649      2.109      0.036       1.521      43.389\nis_beige        47.1551     18.137      2.600      0.010      11.502      82.808\nis_black        -0.4298     21.403     -0.020      0.984     -42.502      41.643\nis_pink          1.0074     26.869      0.037      0.970     -51.810      53.825\nis_blue         -1.5164     22.132     -0.069      0.945     -45.022      41.989\nis_red          -8.5256     23.222     -0.367      0.714     -54.175      37.123\n==============================================================================\nOmnibus:                      354.484   Durbin-Watson:                   1.938\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             8130.115\nSkew:                           3.461   Prob(JB):                         0.00\nKurtosis:                      23.278   Cond. No.                     5.76e+17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 6.75e-32. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train, X_train.astype(float)).fit()\n",
    "predictions = model.predict(X_train) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             prod_price   R-squared:                       0.254\nModel:                            OLS   Adj. R-squared:                  0.247\nMethod:                 Least Squares   F-statistic:                     35.84\nDate:                Wed, 24 Feb 2021   Prob (F-statistic):           8.97e-26\nTime:                        19:40:57   Log-Likelihood:                -2389.8\nNo. Observations:                 425   AIC:                             4790.\nDf Residuals:                     420   BIC:                             4810.\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nconst           11.5689      4.090      2.828      0.005       3.529      19.609\nvolume_avg    2.527e-14   3.13e-15      8.075      0.000    1.91e-14    3.14e-14\ndiameter_avg    -1.5858      0.492     -3.223      0.001      -2.553      -0.619\nis_white        97.6668      8.534     11.444      0.000      80.892     114.442\nis_grey         20.3720      9.894      2.059      0.040       0.924      39.820\nis_beige        39.1240     16.916      2.313      0.021       5.873      72.375\n==============================================================================\nOmnibus:                      356.260   Durbin-Watson:                   1.943\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             8174.117\nSkew:                           3.488   Prob(JB):                         0.00\nKurtosis:                      23.321   Cond. No.                     3.14e+17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.26e-31. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.drop('in_outdoor', axis=1)\n",
    "model = sm.OLS(y_train, X_train.astype(float)).fit()\n",
    "predictions = model.predict(X_train) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2544747001773906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()  # create object for the class\n",
    "model.fit(X_train, y_train)  \n",
    "y_pred = model.predict(X_train)  \n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "\n",
    "print(score)\n",
    "\n",
    "\n",
    "# Drop Columns\n",
    "# Regularisation --> Look at L1 and L2 regularisation and use Alpha\n",
    "# Decision Tree, hyperparameter optimisation with Grid search CV\n",
    "# Model Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.11793368819773783\nBest Hyperparameters: {'alpha': 59.955776229894, 'fit_intercept': False, 'normalize': True, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['solver'] = ['lsqr']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True]\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=300, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "14   {'alpha': 59.955776229894, 'fit_intercept': Fa...         0.117934   \n",
       "145  {'alpha': 53.60691757484734, 'fit_intercept': ...         0.117255   \n",
       "287  {'alpha': 74.98882291237335, 'fit_intercept': ...         0.117224   \n",
       "296  {'alpha': 45.53616986100704, 'fit_intercept': ...         0.109822   \n",
       "41   {'alpha': 44.62384308029314, 'fit_intercept': ...         0.109342   \n",
       "..                                                 ...              ...   \n",
       "268  {'alpha': 1.6836874175707766e-05, 'fit_interce...        -0.077372   \n",
       "284  {'alpha': 1.5648886546097327e-05, 'fit_interce...        -0.077372   \n",
       "144  {'alpha': 1.414730240660428e-05, 'fit_intercep...        -0.077372   \n",
       "80   {'alpha': 1.3777199171605851e-05, 'fit_interce...        -0.077372   \n",
       "135  {'alpha': 1.1376769904708396e-05, 'fit_interce...        -0.077372   \n",
       "\n",
       "     mean_train_score  \n",
       "14           0.191299  \n",
       "145          0.197993  \n",
       "287          0.176726  \n",
       "296          0.207014  \n",
       "41           0.208068  \n",
       "..                ...  \n",
       "268          0.260905  \n",
       "284          0.260905  \n",
       "144          0.260905  \n",
       "80           0.260905  \n",
       "135          0.260905  \n",
       "\n",
       "[300 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>{'alpha': 59.955776229894, 'fit_intercept': Fa...</td>\n      <td>0.117934</td>\n      <td>0.191299</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>{'alpha': 53.60691757484734, 'fit_intercept': ...</td>\n      <td>0.117255</td>\n      <td>0.197993</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>{'alpha': 74.98882291237335, 'fit_intercept': ...</td>\n      <td>0.117224</td>\n      <td>0.176726</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>{'alpha': 45.53616986100704, 'fit_intercept': ...</td>\n      <td>0.109822</td>\n      <td>0.207014</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>{'alpha': 44.62384308029314, 'fit_intercept': ...</td>\n      <td>0.109342</td>\n      <td>0.208068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>{'alpha': 1.6836874175707766e-05, 'fit_interce...</td>\n      <td>-0.077372</td>\n      <td>0.260905</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>{'alpha': 1.5648886546097327e-05, 'fit_interce...</td>\n      <td>-0.077372</td>\n      <td>0.260905</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>{'alpha': 1.414730240660428e-05, 'fit_intercep...</td>\n      <td>-0.077372</td>\n      <td>0.260905</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>{'alpha': 1.3777199171605851e-05, 'fit_interce...</td>\n      <td>-0.077372</td>\n      <td>0.260905</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>{'alpha': 1.1376769904708396e-05, 'fit_interce...</td>\n      <td>-0.077372</td>\n      <td>0.260905</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "lst = ['params','mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2543994945847923\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.1) \n",
    "model.fit(X_train, y_train) \n",
    "y_pred = model.predict(X_train)  # make predictions\n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.30689188938731093\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=2)\n",
    "model.fit(X_train, y_train) \n",
    "y_pred = model.predict(X_train)  # make predictions\n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3450593307276937\n"
     ]
    }
   ],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y_train)\n",
    "y_pred = model.predict(x_poly)\n",
    "score = model.score(x_poly, y_train)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "# model.fit(X_train, y_train)  \n",
    "# y_pred = model.predict(X_train)  \n",
    "# score = model.score(X_train, y_train)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "# space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "# space['solver'] = ['lsqr']\n",
    "# space['alpha'] = loguniform(1e-5, 100)\n",
    "# space['fit_intercept'] = [True, False]\n",
    "# space['normalize'] = [True, False]\n",
    "\n",
    "space['min_samples_leaf'] = [2,4,5,6,10]\n",
    "space['max_depth'] = [2,4,5,6,7,8]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# Return Train\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.031910850088390424\nBest Hyperparameters: {'min_samples_leaf': 5, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "# model.fit(X_train, y_train)  \n",
    "# y_pred = model.predict(X_train)  \n",
    "# score = model.score(X_train, y_train)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "# space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "# space['solver'] = ['lsqr']\n",
    "# space['alpha'] = loguniform(1e-5, 100)\n",
    "# space['fit_intercept'] = [True, False]\n",
    "# space['normalize'] = [True, False]\n",
    "\n",
    "space['min_samples_leaf'] = [2,4,5,6,10]\n",
    "space['max_depth'] = [2,4,5,6,7,8]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# Return Train\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "15   {'min_samples_leaf': 5, 'max_depth': 9}         0.044943   \n",
       "9    {'min_samples_leaf': 3, 'max_depth': 8}         0.043100   \n",
       "1    {'min_samples_leaf': 3, 'max_depth': 6}         0.041636   \n",
       "7    {'min_samples_leaf': 5, 'max_depth': 7}         0.041158   \n",
       "10   {'min_samples_leaf': 4, 'max_depth': 8}         0.040726   \n",
       "13   {'min_samples_leaf': 3, 'max_depth': 9}         0.038449   \n",
       "5    {'min_samples_leaf': 3, 'max_depth': 7}         0.037897   \n",
       "18  {'min_samples_leaf': 4, 'max_depth': 10}         0.037836   \n",
       "14   {'min_samples_leaf': 4, 'max_depth': 9}         0.036193   \n",
       "19  {'min_samples_leaf': 5, 'max_depth': 10}         0.034989   \n",
       "3    {'min_samples_leaf': 5, 'max_depth': 6}         0.034192   \n",
       "2    {'min_samples_leaf': 4, 'max_depth': 6}         0.029622   \n",
       "6    {'min_samples_leaf': 4, 'max_depth': 7}         0.028673   \n",
       "17  {'min_samples_leaf': 3, 'max_depth': 10}         0.026592   \n",
       "11   {'min_samples_leaf': 5, 'max_depth': 8}         0.018481   \n",
       "12   {'min_samples_leaf': 2, 'max_depth': 9}        -0.000482   \n",
       "4    {'min_samples_leaf': 2, 'max_depth': 7}        -0.005859   \n",
       "8    {'min_samples_leaf': 2, 'max_depth': 8}        -0.014873   \n",
       "16  {'min_samples_leaf': 2, 'max_depth': 10}        -0.016880   \n",
       "0    {'min_samples_leaf': 2, 'max_depth': 6}        -0.022949   \n",
       "\n",
       "    mean_train_score  \n",
       "15          0.310817  \n",
       "9           0.322292  \n",
       "1           0.322456  \n",
       "7           0.310801  \n",
       "10          0.311366  \n",
       "13          0.322888  \n",
       "5           0.322442  \n",
       "18          0.311424  \n",
       "14          0.311418  \n",
       "19          0.310769  \n",
       "3           0.310858  \n",
       "2           0.311326  \n",
       "6           0.311346  \n",
       "17          0.322471  \n",
       "11          0.310823  \n",
       "12          0.342302  \n",
       "4           0.342599  \n",
       "8           0.342671  \n",
       "16          0.342715  \n",
       "0           0.343028  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 9}</td>\n      <td>0.044943</td>\n      <td>0.310817</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 8}</td>\n      <td>0.043100</td>\n      <td>0.322292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 6}</td>\n      <td>0.041636</td>\n      <td>0.322456</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 7}</td>\n      <td>0.041158</td>\n      <td>0.310801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 8}</td>\n      <td>0.040726</td>\n      <td>0.311366</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 9}</td>\n      <td>0.038449</td>\n      <td>0.322888</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 7}</td>\n      <td>0.037897</td>\n      <td>0.322442</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 10}</td>\n      <td>0.037836</td>\n      <td>0.311424</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 9}</td>\n      <td>0.036193</td>\n      <td>0.311418</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 10}</td>\n      <td>0.034989</td>\n      <td>0.310769</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 6}</td>\n      <td>0.034192</td>\n      <td>0.310858</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 6}</td>\n      <td>0.029622</td>\n      <td>0.311326</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 7}</td>\n      <td>0.028673</td>\n      <td>0.311346</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 10}</td>\n      <td>0.026592</td>\n      <td>0.322471</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 8}</td>\n      <td>0.018481</td>\n      <td>0.310823</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 9}</td>\n      <td>-0.000482</td>\n      <td>0.342302</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 7}</td>\n      <td>-0.005859</td>\n      <td>0.342599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 8}</td>\n      <td>-0.014873</td>\n      <td>0.342671</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 10}</td>\n      <td>-0.016880</td>\n      <td>0.342715</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 6}</td>\n      <td>-0.022949</td>\n      <td>0.343028</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "lst = ['params', 'mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.044942692685740235\nBest Hyperparameters: {'min_samples_leaf': 5, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "# model.fit(X_train, y_train)  \n",
    "# y_pred = model.predict(X_train)  \n",
    "# score = model.score(X_train, y_train)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "# space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "# space['solver'] = ['lsqr']\n",
    "# space['alpha'] = loguniform(1e-5, 100)\n",
    "# space['fit_intercept'] = [True, False]\n",
    "# space['normalize'] = [True, False]\n",
    "\n",
    "space['min_samples_leaf'] = [2,3,4,5]\n",
    "space['max_depth'] = [6,7,8,9,10]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "15   {'min_samples_leaf': 5, 'max_depth': 9}         0.044943   \n",
       "9    {'min_samples_leaf': 3, 'max_depth': 8}         0.043100   \n",
       "1    {'min_samples_leaf': 3, 'max_depth': 6}         0.041636   \n",
       "7    {'min_samples_leaf': 5, 'max_depth': 7}         0.041158   \n",
       "10   {'min_samples_leaf': 4, 'max_depth': 8}         0.040726   \n",
       "13   {'min_samples_leaf': 3, 'max_depth': 9}         0.038449   \n",
       "5    {'min_samples_leaf': 3, 'max_depth': 7}         0.037897   \n",
       "18  {'min_samples_leaf': 4, 'max_depth': 10}         0.037836   \n",
       "14   {'min_samples_leaf': 4, 'max_depth': 9}         0.036193   \n",
       "19  {'min_samples_leaf': 5, 'max_depth': 10}         0.034989   \n",
       "3    {'min_samples_leaf': 5, 'max_depth': 6}         0.034192   \n",
       "2    {'min_samples_leaf': 4, 'max_depth': 6}         0.029622   \n",
       "6    {'min_samples_leaf': 4, 'max_depth': 7}         0.028673   \n",
       "17  {'min_samples_leaf': 3, 'max_depth': 10}         0.026592   \n",
       "11   {'min_samples_leaf': 5, 'max_depth': 8}         0.018481   \n",
       "12   {'min_samples_leaf': 2, 'max_depth': 9}        -0.000482   \n",
       "4    {'min_samples_leaf': 2, 'max_depth': 7}        -0.005859   \n",
       "8    {'min_samples_leaf': 2, 'max_depth': 8}        -0.014873   \n",
       "16  {'min_samples_leaf': 2, 'max_depth': 10}        -0.016880   \n",
       "0    {'min_samples_leaf': 2, 'max_depth': 6}        -0.022949   \n",
       "\n",
       "    mean_train_score  \n",
       "15          0.310817  \n",
       "9           0.322292  \n",
       "1           0.322456  \n",
       "7           0.310801  \n",
       "10          0.311366  \n",
       "13          0.322888  \n",
       "5           0.322442  \n",
       "18          0.311424  \n",
       "14          0.311418  \n",
       "19          0.310769  \n",
       "3           0.310858  \n",
       "2           0.311326  \n",
       "6           0.311346  \n",
       "17          0.322471  \n",
       "11          0.310823  \n",
       "12          0.342302  \n",
       "4           0.342599  \n",
       "8           0.342671  \n",
       "16          0.342715  \n",
       "0           0.343028  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 9}</td>\n      <td>0.044943</td>\n      <td>0.310817</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 8}</td>\n      <td>0.043100</td>\n      <td>0.322292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 6}</td>\n      <td>0.041636</td>\n      <td>0.322456</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 7}</td>\n      <td>0.041158</td>\n      <td>0.310801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 8}</td>\n      <td>0.040726</td>\n      <td>0.311366</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 9}</td>\n      <td>0.038449</td>\n      <td>0.322888</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 7}</td>\n      <td>0.037897</td>\n      <td>0.322442</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 10}</td>\n      <td>0.037836</td>\n      <td>0.311424</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 9}</td>\n      <td>0.036193</td>\n      <td>0.311418</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 10}</td>\n      <td>0.034989</td>\n      <td>0.310769</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 6}</td>\n      <td>0.034192</td>\n      <td>0.310858</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 6}</td>\n      <td>0.029622</td>\n      <td>0.311326</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 7}</td>\n      <td>0.028673</td>\n      <td>0.311346</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 10}</td>\n      <td>0.026592</td>\n      <td>0.322471</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 8}</td>\n      <td>0.018481</td>\n      <td>0.310823</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 9}</td>\n      <td>-0.000482</td>\n      <td>0.342302</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 7}</td>\n      <td>-0.005859</td>\n      <td>0.342599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 8}</td>\n      <td>-0.014873</td>\n      <td>0.342671</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 10}</td>\n      <td>-0.016880</td>\n      <td>0.342715</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 6}</td>\n      <td>-0.022949</td>\n      <td>0.343028</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "lst = ['params','mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}