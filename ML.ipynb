{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by [Gameli Ladzekpo](mailto:gameli.Ladzekpo@gmail.com) (Twitter/IG: @gamladz)\n",
    "\n",
    "For [AI Core](theaicore.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv') \n",
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.11801338988452151\nBest Hyperparameters: {'alpha': 63.11903032841424, 'fit_intercept': False, 'normalize': True, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "# Randomised Search CV with Linear regression - Ridge Classifer\n",
    "\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['solver'] = ['lsqr']\n",
    "space['alpha'] = loguniform(40, 70)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True]\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=300, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "161  {'alpha': 63.11903032841424, 'fit_intercept': ...         0.118013   \n",
       "89   {'alpha': 63.04471742845627, 'fit_intercept': ...         0.118013   \n",
       "170  {'alpha': 63.60643560750118, 'fit_intercept': ...         0.118013   \n",
       "232  {'alpha': 62.574433169288575, 'fit_intercept':...         0.118010   \n",
       "186  {'alpha': 62.50526054241915, 'fit_intercept': ...         0.118009   \n",
       "..                                                 ...              ...   \n",
       "243  {'alpha': 68.68249490276317, 'fit_intercept': ...        -0.051234   \n",
       "285  {'alpha': 69.4903737367453, 'fit_intercept': T...        -0.051339   \n",
       "114  {'alpha': 69.55547685816778, 'fit_intercept': ...        -0.051347   \n",
       "244  {'alpha': 69.76195992914303, 'fit_intercept': ...        -0.051373   \n",
       "291  {'alpha': 69.77959906669437, 'fit_intercept': ...        -0.051375   \n",
       "\n",
       "     mean_train_score  \n",
       "161          0.188087  \n",
       "89           0.188162  \n",
       "170          0.187599  \n",
       "232          0.188634  \n",
       "186          0.188704  \n",
       "..                ...  \n",
       "243          0.007830  \n",
       "285          0.007741  \n",
       "114          0.007734  \n",
       "244          0.007712  \n",
       "291          0.007710  \n",
       "\n",
       "[300 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>161</th>\n      <td>{'alpha': 63.11903032841424, 'fit_intercept': ...</td>\n      <td>0.118013</td>\n      <td>0.188087</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>{'alpha': 63.04471742845627, 'fit_intercept': ...</td>\n      <td>0.118013</td>\n      <td>0.188162</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>{'alpha': 63.60643560750118, 'fit_intercept': ...</td>\n      <td>0.118013</td>\n      <td>0.187599</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>{'alpha': 62.574433169288575, 'fit_intercept':...</td>\n      <td>0.118010</td>\n      <td>0.188634</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>{'alpha': 62.50526054241915, 'fit_intercept': ...</td>\n      <td>0.118009</td>\n      <td>0.188704</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>{'alpha': 68.68249490276317, 'fit_intercept': ...</td>\n      <td>-0.051234</td>\n      <td>0.007830</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>{'alpha': 69.4903737367453, 'fit_intercept': T...</td>\n      <td>-0.051339</td>\n      <td>0.007741</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>{'alpha': 69.55547685816778, 'fit_intercept': ...</td>\n      <td>-0.051347</td>\n      <td>0.007734</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>{'alpha': 69.76195992914303, 'fit_intercept': ...</td>\n      <td>-0.051373</td>\n      <td>0.007712</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>{'alpha': 69.77959906669437, 'fit_intercept': ...</td>\n      <td>-0.051375</td>\n      <td>0.007710</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "lst = ['params','mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.03185043038500567\nBest Hyperparameters: {'min_samples_leaf': 10, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# Randomised search with decison Tree Regressor\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "\n",
    "space = dict()\n",
    "space['min_samples_leaf'] = [2,4,5,6,10]\n",
    "space['max_depth'] = [2,4,5,6,7,8]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# Return Train\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.031910850088390424\nBest Hyperparameters: {'min_samples_leaf': 5, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "# Randomised search with decison Tree Regressor\n",
    "\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "\n",
    "space['min_samples_leaf'] = [2,4,5,6,10]\n",
    "space['max_depth'] = [2,4,5,6,7,8]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# Return Train\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "15   {'min_samples_leaf': 5, 'max_depth': 9}         0.044943   \n",
       "9    {'min_samples_leaf': 3, 'max_depth': 8}         0.043100   \n",
       "1    {'min_samples_leaf': 3, 'max_depth': 6}         0.041636   \n",
       "7    {'min_samples_leaf': 5, 'max_depth': 7}         0.041158   \n",
       "10   {'min_samples_leaf': 4, 'max_depth': 8}         0.040726   \n",
       "13   {'min_samples_leaf': 3, 'max_depth': 9}         0.038449   \n",
       "5    {'min_samples_leaf': 3, 'max_depth': 7}         0.037897   \n",
       "18  {'min_samples_leaf': 4, 'max_depth': 10}         0.037836   \n",
       "14   {'min_samples_leaf': 4, 'max_depth': 9}         0.036193   \n",
       "19  {'min_samples_leaf': 5, 'max_depth': 10}         0.034989   \n",
       "3    {'min_samples_leaf': 5, 'max_depth': 6}         0.034192   \n",
       "2    {'min_samples_leaf': 4, 'max_depth': 6}         0.029622   \n",
       "6    {'min_samples_leaf': 4, 'max_depth': 7}         0.028673   \n",
       "17  {'min_samples_leaf': 3, 'max_depth': 10}         0.026592   \n",
       "11   {'min_samples_leaf': 5, 'max_depth': 8}         0.018481   \n",
       "12   {'min_samples_leaf': 2, 'max_depth': 9}        -0.000482   \n",
       "4    {'min_samples_leaf': 2, 'max_depth': 7}        -0.005859   \n",
       "8    {'min_samples_leaf': 2, 'max_depth': 8}        -0.014873   \n",
       "16  {'min_samples_leaf': 2, 'max_depth': 10}        -0.016880   \n",
       "0    {'min_samples_leaf': 2, 'max_depth': 6}        -0.022949   \n",
       "\n",
       "    mean_train_score  \n",
       "15          0.310817  \n",
       "9           0.322292  \n",
       "1           0.322456  \n",
       "7           0.310801  \n",
       "10          0.311366  \n",
       "13          0.322888  \n",
       "5           0.322442  \n",
       "18          0.311424  \n",
       "14          0.311418  \n",
       "19          0.310769  \n",
       "3           0.310858  \n",
       "2           0.311326  \n",
       "6           0.311346  \n",
       "17          0.322471  \n",
       "11          0.310823  \n",
       "12          0.342302  \n",
       "4           0.342599  \n",
       "8           0.342671  \n",
       "16          0.342715  \n",
       "0           0.343028  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 9}</td>\n      <td>0.044943</td>\n      <td>0.310817</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 8}</td>\n      <td>0.043100</td>\n      <td>0.322292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 6}</td>\n      <td>0.041636</td>\n      <td>0.322456</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 7}</td>\n      <td>0.041158</td>\n      <td>0.310801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 8}</td>\n      <td>0.040726</td>\n      <td>0.311366</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 9}</td>\n      <td>0.038449</td>\n      <td>0.322888</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 7}</td>\n      <td>0.037897</td>\n      <td>0.322442</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 10}</td>\n      <td>0.037836</td>\n      <td>0.311424</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 9}</td>\n      <td>0.036193</td>\n      <td>0.311418</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 10}</td>\n      <td>0.034989</td>\n      <td>0.310769</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 6}</td>\n      <td>0.034192</td>\n      <td>0.310858</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 6}</td>\n      <td>0.029622</td>\n      <td>0.311326</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 7}</td>\n      <td>0.028673</td>\n      <td>0.311346</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 10}</td>\n      <td>0.026592</td>\n      <td>0.322471</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 8}</td>\n      <td>0.018481</td>\n      <td>0.310823</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 9}</td>\n      <td>-0.000482</td>\n      <td>0.342302</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 7}</td>\n      <td>-0.005859</td>\n      <td>0.342599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 8}</td>\n      <td>-0.014873</td>\n      <td>0.342671</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 10}</td>\n      <td>-0.016880</td>\n      <td>0.342715</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 6}</td>\n      <td>-0.022949</td>\n      <td>0.343028</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "lst = ['params', 'mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score: 0.044942692685740235\nBest Hyperparameters: {'min_samples_leaf': 5, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "# Randomised search with Random Forest Regressor\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['min_samples_leaf'] = [2,3,4,5]\n",
    "space['max_depth'] = [6,7,8,9,10]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=30, scoring='r2', n_jobs=-1, cv=cv, random_state=1, return_train_score=True)\n",
    "result = search.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "15   {'min_samples_leaf': 5, 'max_depth': 9}         0.044943   \n",
       "9    {'min_samples_leaf': 3, 'max_depth': 8}         0.043100   \n",
       "1    {'min_samples_leaf': 3, 'max_depth': 6}         0.041636   \n",
       "7    {'min_samples_leaf': 5, 'max_depth': 7}         0.041158   \n",
       "10   {'min_samples_leaf': 4, 'max_depth': 8}         0.040726   \n",
       "13   {'min_samples_leaf': 3, 'max_depth': 9}         0.038449   \n",
       "5    {'min_samples_leaf': 3, 'max_depth': 7}         0.037897   \n",
       "18  {'min_samples_leaf': 4, 'max_depth': 10}         0.037836   \n",
       "14   {'min_samples_leaf': 4, 'max_depth': 9}         0.036193   \n",
       "19  {'min_samples_leaf': 5, 'max_depth': 10}         0.034989   \n",
       "3    {'min_samples_leaf': 5, 'max_depth': 6}         0.034192   \n",
       "2    {'min_samples_leaf': 4, 'max_depth': 6}         0.029622   \n",
       "6    {'min_samples_leaf': 4, 'max_depth': 7}         0.028673   \n",
       "17  {'min_samples_leaf': 3, 'max_depth': 10}         0.026592   \n",
       "11   {'min_samples_leaf': 5, 'max_depth': 8}         0.018481   \n",
       "12   {'min_samples_leaf': 2, 'max_depth': 9}        -0.000482   \n",
       "4    {'min_samples_leaf': 2, 'max_depth': 7}        -0.005859   \n",
       "8    {'min_samples_leaf': 2, 'max_depth': 8}        -0.014873   \n",
       "16  {'min_samples_leaf': 2, 'max_depth': 10}        -0.016880   \n",
       "0    {'min_samples_leaf': 2, 'max_depth': 6}        -0.022949   \n",
       "\n",
       "    mean_train_score  \n",
       "15          0.310817  \n",
       "9           0.322292  \n",
       "1           0.322456  \n",
       "7           0.310801  \n",
       "10          0.311366  \n",
       "13          0.322888  \n",
       "5           0.322442  \n",
       "18          0.311424  \n",
       "14          0.311418  \n",
       "19          0.310769  \n",
       "3           0.310858  \n",
       "2           0.311326  \n",
       "6           0.311346  \n",
       "17          0.322471  \n",
       "11          0.310823  \n",
       "12          0.342302  \n",
       "4           0.342599  \n",
       "8           0.342671  \n",
       "16          0.342715  \n",
       "0           0.343028  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 9}</td>\n      <td>0.044943</td>\n      <td>0.310817</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 8}</td>\n      <td>0.043100</td>\n      <td>0.322292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 6}</td>\n      <td>0.041636</td>\n      <td>0.322456</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 7}</td>\n      <td>0.041158</td>\n      <td>0.310801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 8}</td>\n      <td>0.040726</td>\n      <td>0.311366</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 9}</td>\n      <td>0.038449</td>\n      <td>0.322888</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 7}</td>\n      <td>0.037897</td>\n      <td>0.322442</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 10}</td>\n      <td>0.037836</td>\n      <td>0.311424</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 9}</td>\n      <td>0.036193</td>\n      <td>0.311418</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 10}</td>\n      <td>0.034989</td>\n      <td>0.310769</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 6}</td>\n      <td>0.034192</td>\n      <td>0.310858</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 6}</td>\n      <td>0.029622</td>\n      <td>0.311326</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'min_samples_leaf': 4, 'max_depth': 7}</td>\n      <td>0.028673</td>\n      <td>0.311346</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>{'min_samples_leaf': 3, 'max_depth': 10}</td>\n      <td>0.026592</td>\n      <td>0.322471</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>{'min_samples_leaf': 5, 'max_depth': 8}</td>\n      <td>0.018481</td>\n      <td>0.310823</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 9}</td>\n      <td>-0.000482</td>\n      <td>0.342302</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 7}</td>\n      <td>-0.005859</td>\n      <td>0.342599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 8}</td>\n      <td>-0.014873</td>\n      <td>0.342671</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 10}</td>\n      <td>-0.016880</td>\n      <td>0.342715</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>{'min_samples_leaf': 2, 'max_depth': 6}</td>\n      <td>-0.022949</td>\n      <td>0.343028</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "lst = ['params','mean_test_score', 'mean_train_score']\n",
    "pd.DataFrame(result.cv_results_).sort_values('mean_test_score', ascending = False)[lst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-ef1ea8b06f48>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-111-ef1ea8b06f48>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    From lookng at all models normalsed ridge regression performs best on the training set.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# From lookng at all models normalsed ridge regression performs best on the training set. \n",
    "\n",
    "# polynomial_features= PolynomialFeatures(degree=2)\n",
    "# x_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(x_poly, y_train)\n",
    "# y_pred = model.predict(x_poly)\n",
    "# score = model.score(x_poly, y_train)\n",
    "# print(score)\n",
    "\n",
    "\n",
    "# Linear Model with Lasso\n",
    "# model = linear_model.Lasso(alpha=0.1) \n",
    "# model.fit(X_train, y_train) \n",
    "# y_pred = model.predict(X_train)  # make predictions\n",
    "# score = model.score(X_train, y_train)\n",
    "# print(score)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "# model = DecisionTreeRegressor(max_depth=2)\n",
    "# model.fit(X_train, y_train) \n",
    "# y_pred = model.predict(X_train)  # make predictions\n",
    "# score = model.score(X_train, y_train)\n",
    "# print(score)\n",
    "\n",
    "# Polynomial Features\n",
    "# polynomial_features= PolynomialFeatures(degree=2)\n",
    "# x_poly = polynomial_features.fit_transform(X_train)\n",
    "# model = LinearRegression()\n",
    "# model.fit(x_poly, y_train)\n",
    "# y_pred = model.predict(x_poly)\n",
    "# score = model.score(x_poly, y_train)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}